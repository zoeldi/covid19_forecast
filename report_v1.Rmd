---
title: "Quantifying the impacts of COVID-19 on human mobility from an official statistics perspective – the case of Hungary"
output: 
  html_notebook: 
    toc: yes
    toc_float: yes
    number_sections: yes
    highlight: pygments
    code_folding: hide
---

```{css}
.main-container {
    max-width: 1700px !important;
    text-align: justify;
}
body{
  font-size: 11pt;
}
pre {
  max-height: 800px !important;
  overflow-y: auto !important;
  overflow-x: auto !important;
}
pre code {
  white-space: pre
}
```

The COVID-19 pandemics put official data producers in a new situation. Decision-makers, researchers, representatives of the media and the general audience demand for high-quality statistics on the wide-ranging socio-economic and demographic impacts of the coronavirus, which – regarding depth and timeliness – had no precedents. Official statisticians mostly reached to satisfy such user needs, backed by innovative solutions both at the level of organization and of data engineering. However, despite the obvious consequences of the pandemics on virtually all aspects of human mobility, satisfactory responses of migration statistics are still scarce. In most part, this is due to the mere statistical definition of migration (linked to the concept of usual residence) that disregards shorter term population movements, thus being unable to capture the fast-changing and diverse universe of geographic mobility. In this paper, a wider sense concept of mobility is applied, which we believe is more appropriate for taking stock of the mobile population in the context of COVID-19. In an attempt of quantifying the impacts of the pandemics on outwards mobility of Hungarian citizens and their return, we carried out interrupted time series analyses and fitted an ensemble machine learning model trained by pre-pandemic time series data of monthly migration flows. First we simulated counterfactual monthly flows for 2020 and 2021 in order to shed lights on how migration patterns would have been evolving, if COVID-19 had not disrupted mobility dynamics. Then we compared such model-based predictions with the actual size of monthly migrations in the same years to make conclusions on how the pandemics affected the mobility patterns of the target population. In accordance with our preliminary results, an immediate shock effect of the coronavirus reduced the size of monthly outflows in the second quarter of 2020, however left intra-annual seasonal trends untouched. The lasting negative effect remained significant in the entire period under consideration. In contrast, changes as regards the levels of return mobility cannot be observed, however the actual seasonal patterns differ from the expected ones: many returners apparently brought forward their homecoming due to the first wave of the pandemics. A further important conclusion we might draw from this study is that a large share of the COVID impacts on migration patterns cannot be revealed unless we develop a more dynamic and more flexible understanding of human mobility.

```{r setup, echo=TRUE, results='hide'}
# options
options(width = 140)
Sys.setlocale("LC_TIME", "English")
knitr::opts_chunk$set(fig.width=13, fig.height=6) 
# colors 
colorblind = list('grey' =   '#999999',
                  'orange' = '#E69F00',
                  'lblue' =  '#56B4E9',
                  'green' =  '#009E73',
                  'yellow' = '#F0E442',
                  'dblue' =  '#0072B2',
                  'red' =    '#D55E00',
                  'pink' =   '#CC79A7')
# path
dir_root = getwd()
dir_data = paste0(dir_root, '\\data')
dir_outp = paste0(dir_root, '\\output')

# libs
if (!require("pacman")) install.packages("pacman")

pacman::p_load(tidyverse,
               tidyquant,
               tidymodels,
               timetk,
               tsibble,
               fabletools,
               feather,
               modeltime,
               modeltime.ensemble)

# load data
dat1 = read_feather(paste0(dir_data, '\\dat_raw_3ho.feather'))
```


# Data

```{r transmute}
# transmute new vars:
dat2 = 
  dat1 %>% 
  transmute(type = code,
            migdate = migdate,
            agegrp = case_when(age <= 21 ~ '00-21',
                               age <= 39 ~ '22-39',
                               TRUE ~ '40-99'),
            hostgrp = case_when(host == 'AUT' ~ 'AUT',
                                host == 'DEU' ~ 'DEU',
                                host %in% c('GBR', 'IRL') ~ 'GRB/IRL',
                                host %in% c('DNK', 'NLD', 'BEL',
                                            'LUX', 'SWE', 'NOR', 'FIN') ~ 'BENELUX/NORDIC',
                                TRUE ~ 'OTH'),
            freq = 1)

# print structure
print(dat2)
```

```{r by flow}
# group by type and pad missing months
dat2_1 = 
  dat2 %>% 
  group_by(type) %>% 
  summarise_by_time(.date_var = migdate,
                    .by = 'month',
                    freq = SUM(freq)) %>% 
  pad_by_time(migdate,
              .by = 'month',
              .pad_value = 1) %>% 
  mutate(freq = log1p(freq / days_in_month(migdate)))

# plot inflow and outflow
plot_time_series(dat2_1,
                 migdate,
                 freq,
                 .facet_ncol = 2,
                 .interactive = F,
                 .facet_scales = 'fixed')
```

```{r by age}
# group by features and pad missing months
dat2_2 = 
  dat2 %>% 
  group_by(type, agegrp) %>% 
  summarise_by_time(.date_var = migdate,
                    .by = 'month',
                    freq = SUM(freq)) %>% 
  pad_by_time(migdate,
              .by = 'month',
              .pad_value = 1) %>% 
  mutate(freq = log1p(freq / days_in_month(migdate))) %>% 
  ungroup()

# plot inflow and outflow
plot_time_series(dat2_2,
                 migdate,
                 freq,
                 .facet_vars = type,
                 .color_var = agegrp,
                 .facet_ncol = 2,
                 .interactive = F,
                 .facet_scales = 'fixed',
                 .smooth = F)
```


```{r by host}
# group by features and pad missing months
dat2_3 = 
  dat2 %>% 
  group_by(type, hostgrp) %>% 
  summarise_by_time(.date_var = migdate,
                    .by = 'month',
                    freq = SUM(freq)) %>% 
  pad_by_time(migdate,
              .by = 'month',
              .pad_value = 1) %>% 
  mutate(freq = log1p(freq / days_in_month(migdate))) %>% 
  ungroup()

# plot inflow and outflow
plot_time_series(dat2_3,
                 migdate,
                 freq,
                 .facet_vars = type,
                 .color_var = hostgrp,
                 .facet_ncol = 2,
                 .interactive = F,
                 .facet_scales = 'fixed',
                 .smooth = F)
```

# Group lists

```{r group id}
# Data for outflow
dat_o = 
  dat2 %>% 
  filter(type == 'Outflow') %>% 
  select(-type) %>%
  # Base level correction: log+1, pad, dayisinmonth denominator
  group_by(agegrp, 
           hostgrp) %>% 
  summarise_by_time(.date_var = migdate,
                    .by = 'month',
                    freq = SUM(freq)) %>% 
  pad_by_time(.date_var = migdate,
              .by = 'month',
              .pad_value = 1,
              .start_date = '2010-01-01') %>% 
  mutate(freq = log1p(freq / days_in_month(migdate))) %>% 
  # transform to tsibble and create aggregates
  as_tsibble(key = c(agegrp, 
                     hostgrp),
             index = migdate) %>% 
  aggregate_key(agegrp * hostgrp, 
                freq = log(sum(exp(freq)))) %>% 
  group_by(agegrp, hostgrp) %>% 
  mutate(ts_id = cur_group_id()) %>% 
  ungroup()
  
# nested ts object
dat_o2 = 
  dat_o %>%
  as_tibble() %>% 
  filter(migdate >= ymd('2011-01-01') & migdate <= ymd('2019-12-01')) %>% 
  select(-agegrp, -hostgrp) %>% 
  extend_timeseries(.id_var = ts_id,
                    .date_var = migdate,
                    .length_future = 24) %>% 
  nest_timeseries(.id_var = ts_id,
                  .length_future = 24,
                  .length_actual = 108) %>% 
  split_nested_timeseries(.length_test = 12)

dat_o2
```



# Recipe

```{r, fig.height=12, fig.width=16}
# Recipes
recipe_1 = 
  recipe(freq ~ migdate, 
         data = extract_nested_train_split(dat_o2))

recipe_2 =
  recipe(freq ~ .,
         data = extract_nested_train_split(dat_o2)) %>% 
  step_timeseries_signature(migdate) %>%
  step_rm(migdate) %>%
  step_zv(all_predictors()) %>%
  step_rm(contains("iso"), 
          contains("second"), contains("minute"), contains("hour"),
          contains("am.pm"), contains("xts"), contains('day'), contains('week')) %>% 
  step_dummy(all_nominal_predictors(), one_hot = TRUE) 

recipe_3 =
  recipe(freq ~ .,
         data = extract_nested_train_split(dat_o2)) %>% 
  step_timeseries_signature(migdate) %>%
  step_fourier(migdate, 
               period = c(12/4), 
               K = 1) %>% 
  step_rm(migdate) %>%
  step_zv(all_predictors()) %>%
  step_rm(contains("iso"), 
          contains("second"), contains("minute"), contains("hour"),
          contains("am.pm"), contains("xts"), contains('day'), contains('week')) %>% 
  step_dummy(all_nominal_predictors(), one_hot = TRUE)

recipe_4 =
  recipe(freq ~ .,
         data = extract_nested_train_split(dat_o2)) %>% 
  step_timeseries_signature(migdate) %>%
  step_fourier(migdate, 
               period = c(12/4), 
               K = 2) %>% 
  step_rm(migdate) %>%
  step_zv(all_predictors()) %>%
  step_rm(contains("iso"), 
          contains("second"), contains("minute"), contains("hour"),
          contains("am.pm"), contains("xts"), contains('day'), contains('week')) %>% 
  step_dummy(all_nominal_predictors(), one_hot = TRUE) 


bake(prep(recipe_2), new_data = extract_nested_train_split(dat_o2))
```

# Models

```{r, fig.height=12, fig.width=16}
# Models
mod_prophet_1 = 
  prophet_reg('regression', 
              seasonality_yearly = TRUE) %>% 
  set_engine('prophet')

mod_xgb_1 = 
  boost_tree('regression') %>% 
  set_engine('xgboost')

model_tbl = 
  tibble(expand_grid(tree_depth = c(3,
                                    4,
                                    5,
                                    6,
                                    7,
                                    8),
                     learn_rate = c(0.001,
                                    0.005,
                                    0.010,
                                    0.050,
                                    0.100,
                                    0.200,
                                    0.300,
                                    0.350,
                                    0.400,
                                    0.500, 
                                    0.650),
                     trees = c(5,
                               10, 
                               15, 
                               20,
                               25,
                               30,
                               35))) %>%
  create_model_grid(f_model_spec = boost_tree,
                    engine_name  = "xgboost",
                    mode         = "regression")

model_list <- model_tbl$.models
```


# Workflows

```{r, fig.height=12, fig.width=16}
# Workflows
wflw_prophet_1 = 
  workflow() %>%
  add_model(mod_prophet_1) %>%
  add_recipe(recipe_1)

wflw_xgb_1 = 
  workflow() %>% 
  add_model(mod_xgb_1) %>% 
  add_recipe(recipe_2)

wflw_xgb_2 = 
  workflow() %>% 
  add_model(mod_xgb_1) %>% 
  add_recipe(recipe_3)

wflw_xgb_3 = 
  workflow() %>% 
  add_model(mod_xgb_1) %>% 
  add_recipe(recipe_4)

model_wfset =
  workflow_set(preproc = list(recipe_2),
  models = model_list, 
  cross = TRUE)

x = sapply(model_wfset[[2]], function(i) i[[1]])
```


# Fit 

```{r, fig.height=12, fig.width=16}
parallel_start(5)

dat_o3 = 
  modeltime_nested_fit(nested_data = dat_o2,
                       model_list = x,
                       control = control_nested_fit(allow_par = T,
                                                    cores = 5,
                                                    verbose = T))

parallel_stop()

dat_o3 %>% 
  extract_nested_test_accuracy() %>%
  table_modeltime_accuracy(.interactive = F)

dat_o3 %>% 
  extract_nested_test_forecast() %>%
  # filter(ts_id == 24) %>% 
  group_by(ts_id) %>%
  plot_modeltime_forecast(
    .facet_ncol  = 5,
    .interactive = FALSE,
    .conf_interval_show = FALSE
  )
```

```{r}
dat_o4 <- dat_o3 %>%
    modeltime_nested_select_best(
      metric                = "rmse", 
      minimize              = TRUE, 
      filter_test_forecasts = TRUE)

dat_o4 %>%
  extract_nested_best_model_report()    
```

```{r, fig.height=12, fig.width=16}
dat_o4 %>%
  extract_nested_test_forecast() %>%
  group_by(ts_id) %>%
  plot_modeltime_forecast(
    .facet_ncol  = 5,
    .interactive = FALSE,
    .conf_interval_show = F
  )
```

```{r, fig.height=12, fig.width=16}
dat_o5 <- dat_o4 %>%
    modeltime_nested_refit(
        control = control_nested_refit(verbose = TRUE)
    )

dat_o5 %>%
  extract_nested_future_forecast() %>%
  group_by(ts_id) %>%
  plot_modeltime_forecast(
    .interactive = FALSE,
    .facet_ncol  = 5,
    .conf_interval_show = F
  )

dat_o5
```



















